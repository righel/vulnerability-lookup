from __future__ import annotations

import json
import logging
import re

from pathlib import Path
from typing import Callable
from uuid import uuid4

import orjson

from ..helpers import fromisoformat_wrapper

from .abstract_feeder import AbstractFeeder


class Vulnrichment(AbstractFeeder):
    def __init__(self) -> None:
        super().__init__(Path(__file__).stem)

        self.init_git_repo()

    def _load_logging_config(self) -> None:
        cur_path = Path(__file__)
        if not (cur_path.parent / f'{cur_path.stem}_logging.json').exists():
            return
        with (cur_path.parent / f'{cur_path.stem}_logging.json').open() as f:
            log_config = orjson.loads(f.read())
        logging.config.dictConfig(log_config)

    def update(self, stop: Callable[..., bool]) -> bool:

        self.git.remotes.origin.pull('develop')

        paths_to_import: set[Path] = set()
        if _last_update := self.storage.hget('last_updates', self.name):
            _last_update_str = _last_update.decode()
            if _last_update_str == self.git.head.commit.hexsha:
                # No changes
                self.logger.info('No new commit.')
                return False
            for commit in self.git.iter_commits(f'{_last_update_str}...HEAD'):
                for line in self.git.git.show(commit.hexsha, name_only=True).split('\n'):
                    if not line.endswith('.json'):
                        continue
                    p_path = self.path_to_repo / Path(line)
                    if p_path.exists() and re.match(r'CVE-\d{4}-\d+.json', p_path.name):
                        paths_to_import.add(p_path)
        else:
            # First run, get all files
            for p_path in self.path_to_repo.rglob('*.json'):
                if p_path.exists() and re.match(r'CVE-\d{4}-\d+.json', p_path.name):
                    paths_to_import.add(p_path)

        if not paths_to_import:
            self.logger.info('Nothing new to import.')
            return False

        import_complete: bool = True
        p = self.storage.pipeline()
        index_vulnrichment: dict[str, float] = {}
        vuln_to_push = []
        for path in paths_to_import:
            cve_id = path.stem.lower()
            with path.open() as vuln_entry:
                vuln = orjson.loads(vuln_entry.read())
            # do we already have a meta entry for this source?
            if _meta_uuid := self.storage.hget(f'{cve_id}:meta', self.name):
                meta_uuid = _meta_uuid.decode()
            else:
                meta_uuid = str(uuid4())
                p.hset(f'{cve_id}:meta', mapping={self.name: meta_uuid})
            # No proper identifier for this source, so we use an UUID
            prepared_entry = {}
            for k, v in vuln.items():
                if not v:
                    continue
                if isinstance(v, (list, set, dict)):
                    prepared_entry[k] = json.dumps(v)
                else:
                    prepared_entry[k] = v
            vuln_to_push.append(orjson.dumps(prepared_entry))
            p.hset(f'{self.name}:{meta_uuid}', mapping=prepared_entry)
            index_vulnrichment[meta_uuid] = fromisoformat_wrapper(vuln['cveMetadata']['dateUpdated']).timestamp()

            if len(index_vulnrichment) > 1000:
                # Avoid a massive execute on first import
                p.zadd(f'index:{self.name}', index_vulnrichment)  # type: ignore
                p.execute()

                # Publish the vulnerabilities
                self.publish(vuln_to_push)

                # reset pipeline
                p = self.storage.pipeline()
                index_vulnrichment = {}

                # Reset the list of vulnerabilities to push
                vuln_to_push = []

            if stop():
                self.logger.info('Shutdown requested. Stopping import.')
                import_complete = False
                break

        if index_vulnrichment:
            # We do not store that in the index key as they are meta
            p.zadd(f'index:{self.name}', index_vulnrichment)  # type: ignore
            p.execute()

            # Publish the vulnerabilities
            self.publish(vuln_to_push)

        if import_complete:
            self.storage.hset('last_updates', mapping={self.name: self.git.head.commit.hexsha})
            self.logger.info('Import done.')
            return True

        return False
